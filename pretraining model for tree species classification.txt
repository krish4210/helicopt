import csv
import string
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img

# Assuming you have a CSV file for tree species classification similar to sign_mnist_train.csv
TRAINING_FILE = 'path_to_your_tree_species_training_csv_file.csv'
VALIDATION_FILE = 'path_to_your_tree_species_validation_csv_file.csv'

# Download the CSV files if necessary
# !gdown --id your_training_file_id
# !gdown --id your_validation_file_id

# Parse data from input files
def parse_data_from_input(filename):
    labels = []
    images = []

    with open(filename, 'r') as file:
        csv_reader = csv.reader(file)
        next(csv_reader)  # Skip the header row

        for row in csv_reader:
            label = int(row[0])  # Extract label (the first value in the row)
            pixel_values = np.array([int(x) for x in row[1:]])  # Extract pixel values

            # Reshape the pixel values from 1D (784,) to 2D (28, 28)
            image = np.reshape(pixel_values, (28, 28)).astype(np.float64)

            labels.append(label)
            images.append(image)

    # Convert lists to numpy arrays
    labels = np.array(labels, dtype=np.float64)
    images = np.array(images, dtype=np.float64)
    return images, labels

# Load training and validation data
training_images, training_labels = parse_data_from_input(TRAINING_FILE)
validation_images, validation_labels = parse_data_from_input(VALIDATION_FILE)

import cv2
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

import os
import cv2

# Path to the directory containing subdirectories for each tree species category
data_directory = 'path/to/your/tree_species_data_directory'

# Initialize empty lists to store image paths and corresponding labels
tree_images_paths = []
tree_labels = []

# Iterate through subdirectories (each subdirectory represents a tree species category)
for category in os.listdir(data_directory):
    category_path = os.path.join(data_directory, category)
    if os.path.isdir(category_path):
        # Iterate through image files in the current category
        for filename in os.listdir(category_path):
            if filename.endswith('.jpg'):  # Assuming images are in JPG format
                # Construct the full path to the image file
                image_path = os.path.join(category_path, filename)
                
                # Load the image in grayscale and resize it to the desired dimensions
                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                img = cv2.resize(img, (28, 28))  # Resize images to (28, 28) if needed
                
                # Append the image path to the list
                tree_images_paths.append(img)
                
                # Append the corresponding label (numeric category) to the labels list
                tree_labels.append(int(category))  # Assuming subdirectory names are numeric labels

# Print the first few image paths and corresponding labels for verification
print("Sample Image Paths:")
print(tree_images_paths[:5])
print("Sample Labels:")
print(tree_labels[:5])


# Load and resize images, convert to grayscale
def load_and_preprocess_images(image_paths, target_size=(28, 28)):
    images = []
    for path in image_paths:
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, target_size)
        images.append(img)
    return np.array(images)

# Load and preprocess tree images
tree_images = load_and_preprocess_images(tree_images_paths)

# Split the data into training and validation sets
train_images, val_images, train_labels, val_labels = train_test_split(
    tree_images, tree_labels, test_size=0.2, random_state=42
)

# Reshape and normalize the image data
train_images = np.expand_dims(train_images, axis=-1) / 255.0
val_images = np.expand_dims(val_images, axis=-1) / 255.0

# One-hot encode the labels
num_classes = len(np.unique(tree_labels))
train_labels = to_categorical(train_labels, num_classes)
val_labels = to_categorical(val_labels, num_classes)

# Print shapes for confirmation
print(f"Training images shape: {train_images.shape}")
print(f"Training labels shape: {train_labels.shape}")
print(f"Validation images shape: {val_images.shape}")
print(f"Validation labels shape: {val_labels.shape}")


# Define a function to create the model
def create_tree_species_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(num_classes, activation='softmax')  # num_classes is the number of tree species categories
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Create the model
num_classes = # specify the number of tree species categories
tree_species_model = create_tree_species_model()

# Data preprocessing and augmentation
# Modify the ImageDataGenerator as per your requirements for data augmentation
datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,
                             height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)

# Prepare the generators
train_generator = datagen.flow(np.expand_dims(training_images, axis=-1), training_labels, batch_size=32)
validation_generator = datagen.flow(np.expand_dims(validation_images, axis=-1), validation_labels, batch_size=32)

# Train the model
history = tree_species_model.fit(train_generator, epochs=15, steps_per_epoch=len(train_generator),
                                 validation_data=validation_generator, validation_steps=len(validation_generator))

# Plot training and validation accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'r', label='Training Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()
